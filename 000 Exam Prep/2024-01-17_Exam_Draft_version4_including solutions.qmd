---
title: "Exam draft (first exam) Ws 24/25"
format: 
  html:
    self-contained: true
    theme: minty
editor: visual
---

# Info on exam

There will be four different tasks with various sub-tasks and the following points:

1.  MC questions - 30p
2.  Code explanation - 20p
3.  Regression - 22p
4.  Regularization and Generalisability - 18p

The exam consists of 90p total.

You are not supposed to answer with handwritten code but rather with "normal" text.

# Task 1: MC Questions (30p)

15 questions, 2p per question -\> 30p

::: callout-note
Please note, that multiple (max. 2) or single answers are possible.
:::

## Task 1.1

Working with R: Given the following matrix in R: `matrix_data <- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3, byrow = TRUE)`. Which R code returns the number of columns in this matrix?

a.  `ncol(matrix_data)`
b.  `nrow(matrix_data)`
c.  `length(matrix_data)`
d.  `dim(matrix_data)[2]`

> **Answer:**
>
> a\. `ncol(matrix_data)`

## Task 1.2

Algorithms: What is the main purpose of an algorithm?

a.  Database management
b.  Automatic generation of graphics
c.  Solving a problem through a sequence of steps
d.  Implementation of hardware components

> **Answer:**
>
> c\. Solving a problem through a sequence of steps

## Task 1.3

Model validation: What is a fundamental step in model validation in Data Science?

a.  Train the model
b.  Collect data
c.  Verify the accuracy of the model with new data
d.  Save the model in a database

> **Answer:**
>
> c\. Verify the accuracy of the model with new data (Junbo: i will rather say model performance instead of accuracy)

## Task 1.4

Model performance: Which term describes the ability of a model to perform well on unseen data?

a.  Overfitting
b.  Generalization
c.  Data cleaning
d.  Underfitting

> **Answer:**
>
> b\. Generalization

## Task 1.5

**What does 'pruning' refer to in the context of decision trees?**

a.  Increasing the number of features considered in the model to provide more complexity.
b.  Aggregating the results of multiple decision trees into a single model for better accuracy.
c.  Refining the model by removing branches that do not significantly contribute to predictive power
d.  Utilizing cross-validation techniques to determine significant branches.

> **Answer:**
>
> c\. Refining the model by removing branches that do not significantly contribute to predictive power

## Task 1.6

**What does dimensionality reduction refer to in data science?**

a.  Expanding the dataset with additional features
b.  removing large values from a dataset
c.  Streamlining the analysis by focusing on a smaller number of relevant variables
d.  Filtering out all categorical variables from the dataset.

> **Answer:**
>
> c\. Streamlining the analysis by focusing on a smaller number of relevant variables

## Task 1.7

Which package in R is commonly used for creating advanced graphics?

a.  ggplot2
b.  dplyr
c.  tidyr
d.  shiny

> **Answer:**
>
> a\. ggplot2

## Task 1.8

In R, what function is commonly used to transform data into a data frame?

a.  matrix()
b.  as.data.frame()
c.  df()
d.  table()

> **Answer**:
>
> b\. as.data.frame()

## Task 1.9 +

What is the primary purpose of a validation set in data science?

a.  To train the model on labeled data.
b.  To evaluate the model's performance during training.
c.  To test the model's final performance on unseen data.
d.  To preprocess and clean the dataset.

> **Answer:**
>
> b\. To evaluate the model's performance during training.

## Task 1.10 +

What is the main objective of regularization as seen in ridge/lasso regression?

a.  To improve training speed by reducing the dataset size.
b.  To handle missing values in the dataset effectively.
c.  To prevent overfitting by penalizing large model coefficients.
d.  To increase the complexity of the model for better accuracy.

> **Answer:**
>
> c\. To prevent overfitting by penalizing large model coefficients.

## Task 1.11 ++

In regularization techniques like Ridge and Lasso regression, what effect does increasing the regularization parameter (\$\lambda\$) have on the model?

a.  It increases the complexity of the model by allowing larger coefficients.
b.  It reduces the magnitude of coefficients, leading to simpler models and less overfitting.
c.  It has no impact on the model's coefficients or complexity.
d.  It increases the model's sensitivity to noise in the training data.

> **Answer:**
>
> b\. It reduces the magnitude of coefficients, leading to simpler models and less overfitting.

## Task 1.12 +

What type of problem is logistic regression primarily used to solve?

a.  Regression problems where the target variable is continuous.
b.  Classification problems where the target variable is categorical.
c.  Clustering problems where the data is grouped into clusters.
d.  Dimensionality reduction problems.

> **Answer**:
>
> b\. Classification problems where the target variable is categorical.

## Task 1.13 +++

Which of the following assumptions is not a requirement for linear regression to produce valid and unbiased results?

a.  Linearity: The relationship between the predictors and the target variable is linear.
b.  Homoscedasticity: The variance of the residuals is constant across all levels of the predictors.
c.  Multicollinearity: Predictors should be highly correlated with each other to improve model stability.
d.  Independence: The residuals are independent of each other.

> **Answer**:
>
> c\. Multicollinearity: Predictors should be highly correlated with each other to improve model stability.

## Task 1.14 +

Which of the following metrics is most commonly used to evaluate the goodness of fit in a linear regression model?

a.  Accuracy
b.  Mean Squared Error (MSE)
c.  F1-score
d.  Precision

> **Answer** :
>
> b\. Mean Squared Error (MSE)

## Task 1.15 +++

When evaluating the performance of a linear regression model, which of the following statements about R-squared (R²) is incorrect?

a.  R² measures the proportion of the variance in the dependent variable that is explained by the independent variables.
b.  A higher R² value indicates a better fit of the model to the data.
c.  R² can never be negative.
d.  R² increases when adding more predictors to the model, even if those predictors do not improve the model.

> **Answer**:
>
> c\. R² can never be negative.

## Task 1.16 ++

In Ordinary Least Squares (OLS) linear regression, which of the following does Residual Sum of Squares (RSS) measure? The equation for RSS is:

```{=tex}
\begin{equation}
RSS = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\end{equation}
```
a.  The total variance explained by the model.
b.  The difference between the predicted and actual values of the dependent variable.
c.  The sum of squared errors between the observed and predicted values.
d.  The amount of variance not explained by the regression model.

> **Answers**:
>
> c\. The sum of squared errors between the observed and predicted values.
>
> d\. The amount of variance not explained by the regression model.

## Task 1.17 +++

When comparing multiple linear regression models, which of the following statements are the most accurate regarding **R-squared (R²)** and **Mean Squared Error (MSE)**?

a\. R² is always the best metric to use when comparing models, regardless of the context.\
b. A higher R² always indicates a better model, even if it leads to overfitting.\
c. MSE is a better metric for evaluating model performance on unseen data.\
d. R² and MSE are used to directly compare models that have different numbers of predictors.

> **Answers:**\
> c. MSE is a better metric for evaluating model performance on unseen data.\
> d. R² and MSE are used to directly compare models that have different numbers of predictors.

## Task 1.18 +

In the context of data science, which of the following best describes the concept of **generalizability**?

a\. The ability of a model to perfectly predict the target variable for the training data.\
b. The ability of a model to identify patterns in a dataset that can be applied to other similar datasets.\
c. The ability of a model to memorize specific examples from the training data.\
d. The ability to visualize and interpret the training data in multiple ways.

> **Answer:**\
> b. The ability of a model to identify patterns in a dataset that can be applied to other similar datasets.

## Task 1.19 +

Which of the following are symptoms of **overfitting** in a linear regression model?

a\. The model performs well on training data but poorly on unseen test data.\
b. The model has high bias and performs poorly on both training and test data.\
c. The model performs well on both training and test data.\
d. The model has high variance and captures noise in the training data.

> **Answers:**\
> a. The model performs well on training data but poorly on unseen test data.\
> d. The model has high variance and captures noise in the training data.

## Task 1.20 ++

After fitting a linear regression model in R using the `lm()` function, you obtain the following output for the model coefficients:

$$\text{(Intercept)} = 5.2, \quad \beta_1 = 2.4, \quad \beta_2 = -0.8$$ Given this model:

$$ \hat{y} = 5.2 + 2.4 \times X_1 - 0.8 \times X_2$$

What can be inferred from $\beta_1$ in this model?

a.  For each unit increase in $X_1$, the predicted value of $y$ will increase by 5.2.
b.  For each unit increase in $X_1$, the predicted value of $y$ will increase by 2.4, assuming $X_2$ remains constant.
c.  For each unit increase in $X_2$, the predicted value of $y$ will decrease by 0.8, assuming $X_1$ remains constant.
d.  The value of $y$ is independent of $X_1$ and only depends on $X_2$.

> **Answers:**\
> b. For each unit increase in $X_1$, the predicted value of $y$ will increase by 2.4, assuming $X_2$ remains constant.
>
> c\. For each unit increase in $X_2$, the predicted value of $y$ will decrease by 0.8, assuming $X_1$ remains constant.

# Task 2: Code explanation - 20p

We will work with `happiness_income_data`. This dataset includes information about different countries and income, satisfaction of the inhabitants, the GDP, income inequality and other variables. Below you get an extensive data description and the tasks.

```{r}
#| echo: false

library(readr)
happiness_income_data <- read_csv("happyscore_income.csv")
#View(happiness_income_data)
happiness_income_data$country...11 <- NULL
happiness_income_data$country <- happiness_income_data$country...1
happiness_income_data$country...1 <- NULL
```

```{r}
#| echo: false
library(openxlsx)
gdp_clean <- read.xlsx("GDP_clean_2023.xlsx")
gdp_clean$GDP_2023 <- as.numeric(gdp_clean$GDP_2023)
gdp_clean$gdp <- gdp_clean$GDP_2023/1000000000
gdp_clean$country <- gdp_clean$Country.Name
gdp_clean$Country.Name <- NULL
gdp_clean$GDP_2023 <- NULL

happiness_income_data <- merge(happiness_income_data, gdp_clean, by.x = "country", by.y="country", all.x = TRUE)

happiness_income_data$GDP <- NULL

happiness_income_data_orig <- happiness_income_data

```

```{r}
#| echo: false
data <- data.frame(
  adjusted_satisfaction = c(37, NA, 60, 59, 65, NA, 43, 63, 37, 34),
  avg_satisfaction = c(4.9, NA, 7.1, 7.2, 7.6, NA, 5.3, 7.2, 4.4, 4.6),
  std_satisfaction = c(2.42, 3.19, 1.91, NA, 1.80, 5.0, 2.10, 1.72, 2.02, 2.57),
  avg_income = c(2096.760, NA, 7101.120, 19457.040, 19917.000, NA, 
                 1265.340, 17168.505, 870.840, 5354.820),
  median_income = c(-999, NA, 5109.400, 16879.620, 15846.060, NA, 
                    994.140, 15166.455, 630.240, 4523.565),
  income_inequality = c(31.44556, NA, -20.56, 30.29625, 35.28500, NA, 
                        32.66500, 113.5, 39.76000, 34.16250),
  region = c('Central and Eastern Europe', 'Sub-Saharan Africa', 
             'Latin America and Caribbean', 'Western Europe', 
             'Australia and New Zealand', NA, 'Southern Asia', 
             'Western Europe', 'Sub-Saharan Africa', 
             'Central and Eastern Europe'),
  happyScore = c(4.350, NA, 12.32, 7.200, 7.284, NA, 4.694, -6.937, 
                 3.587, 4.218),
  gdp = c(14.08, NA, 800, NA, -1.3, NA, 0.39753, 
          261.4, 0.25812, NA),
  country = c('Malawi', 'Zambia', 'Guatemala', 'Sierra Leone', 
              'Panama', NA, 'Burundi', 'Kazakhstan', 
              'Ghana', 'Laos')
)


happiness_income_data <- rbind(happiness_income_data, data)

#install.packages("openxlsx")
#library(openxlsx)
#write.xlsx(happiness_income_data, 'export.xlsx')
```

### Data Description:

The dataset consists of 111 observations. You will work with a subset in task 2.1, and the full data set in task 2.2 and task 2.

| name                  | valuetype | scale                  | explanation                                                                                             |
|------------------|------------------|------------------|-------------------|
| adjusted_satisfaction | numeric   | 0 to 100               | lower values indicate lower life satisfaction, higher values indicate higher life satisfaction          |
| avg_income            | numeric   | 0\$ to thousands of \$ | average annual income in \$                                                                             |
| median_income         | numeric   | 0\$ to thousands of \$ | median annual income in \$                                                                              |
| income_inequality     | numeric   | 0 to 100               | income inequality, lower values indicate a lower inequality, higher values indicate a higher inequality |
| happyScore            | numeric   | 0-10                   | lower values indicate a lower overall happiness, higher values indicate a higher overall happiness      |
| gdp                   | numeric   |                        | GDP in trillions of \$ (Milliarden auf deutsch)                                                         |
| country               | character | \-                     | country name                                                                                            |

## Task 2.1 (14p)

2.1.1. Below is a subset of the dataset happiness_income_data. The code applies steps for data cleaning (i.e., dealing with missing values and outliers). **Follow the steps in the code and update the table by hand. Your final table should be happiness_data_clean** (8p).

> *answer: 1p for each correctly changed value and eliminated row*

```{r}
   # load("happiness_income_data.RData") #loading data
load("happiness_income_data.RData")

happiness_income_data$happyScore <- ifelse(happiness_income_data$happyScore > 10, NA, happiness_income_data$happyScore)

happiness_income_data$median_income <- ifelse(happiness_income_data$median_income < 0, NA, happiness_income_data$median_income)

happiness_income_data$income_inequality <- ifelse(happiness_income_data$income_inequality < 0 | happiness_income_data$income_inequality > 100, NA, happiness_income_data$income_inequality)

happiness_income_data_clean <- na.omit(happiness_income_data)

```

![](tabelle_Klausur.PNG)

**2.1.2. Did you remove singular values and/or rows and/or columns? If you did so, explain why. (2p)**

> *answer*: *4 rows were removed due to including NAs*

**2.1.3. Did you change the content or name of singular values and/or rows and/or columns? If you did so, explain why. (2p)**

> *answer: 4 values were changed to NA, because they were below/above the allowed value range*

**2.1.3. After applying the code: Are any values left that could potentially lead to problems? If so, how could we fix that problem (answer verbally, no code needed)? (2p)**

> *answer: for happyScore a negative value remains that potentially causes distortion*

![](tabelle_Klausur_solution.PNG)

## Task 2.2 - 6p

After the listed data transformation steps we apply a linear regression to our full data set (111 observations) and are left with this output:

```{r}
#| echo: false
happiness_income_data_clean <- happiness_income_data_orig 
happiness_income_data_clean <- na.omit(happiness_income_data_clean)
#make sure the students have the dataset with real values, not the missings/errors that were intentionally included in task 1.1
summary(happiness_income_data_clean)
```

```{r}
options(scipen=999)
model1 <- lm(adjusted_satisfaction ~ avg_income, happiness_income_data_clean)
summary(model1)
```

2.2.1. Explain **which of these graphs illustrates the results of the linear regression (model1) best** and **why** it is the best illustration? (3p)

> *answer: Graph1 illustrates the results of the linear regression best (1p) since it includes a straight line that starts at an adjusted satisfaction of around 40 - so at the intercept b0 of the regression output (1p). Model1 proclaims that with each additional \$ in the average income the adjusted satisfaction raises by 0.0014197 points - meaning that with additional 1000\$ in average income the adjusted satisfaction should rise by about 1.42points which is the case for the blue line in graph1 (1p)*

2.2.2. Why are the other graphics not suitable? (1p each)

Graph 1

```{r}
#| echo: false

library(ggplot2)
  ggplot(data=happiness_income_data_clean, mapping = aes(x=avg_income, y=adjusted_satisfaction)) +
    geom_point() +
    geom_smooth(method = lm, formula = y ~ x) +
    scale_x_continuous(breaks = seq(0, 25000, 1000)) +
    scale_y_continuous(breaks = seq(0, 80, 10)) +
  theme(axis.text.x = element_text(angle = 45), axis.text.y = element_text(angle = 45)) +
    xlab("average annual income in $") +
    ylab("adjusted satisfaction")
```

Graph 2

```{r}
#| echo: false
library(ggplot2)
ggplot(data=happiness_income_data_clean, mapping = aes(x = avg_income, y=adjusted_satisfaction)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2)) +
 xlab("average annual income in $") +
    ylab("adjusted satisfaction")

```

> *answer: Graph2 represents a polynomial regression degree 2 and therefore does not represent the linear regression results of our model correctly. The line is warped and not straight (1p)*

Graph 3

```{r}
#| echo: false
library(ggplot2)
ggplot(data=happiness_income_data_clean, mapping = aes(x = avg_income, y=adjusted_satisfaction)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ poly(x, 7)) +
 xlab("average annual income in $") +
    ylab("adjusted satisfaction")

```

> *answer: Graph3 represents a polynomial regression degree 7 and therefore does not represent the linear regression results of our model correctly. The line is wavy and not straight (1p)*

Graph 4

```{r}
#| echo: false
ggplot(data=happiness_income_data_clean, mapping = aes(x=avg_income, y=adjusted_satisfaction)) +
    geom_point() +
    geom_smooth(method = lm) +
    theme(axis.ticks = element_blank(),     
          axis.text.x = element_blank(),
          axis.text.y = element_blank()) +
 xlab("average annual income in $") +
    ylab("adjusted satisfaction")
```

> *answer: Graph4 consists of a straight line similar to Graph1 but we cannot see specific values since the axis labels and tick-marks as well as scales are completely missing (1p)*

# Task 3: Regression - 22p

3.1. **What kind of question do the different models answer?** Think of a research question for `model1` and of a research question for `model2`. (2p each) –\> 4p total

> *answer: model1: How do a countries income inequality, gdp and median income influence the happyScore? (2p)*
>
> *answer: model2: How do income inequality, gdp and median income influence the chances that a country has a high happyScore (7 or more points)? (2p)*

3.2. **Explain each model in your own words** –\> 1p each, 2p total

> *answer: model1: In the first model we assume a linear relationship between the happyScore of a country and its characteristics such as income inequality, gdp and median income.\
> answer: model2: In the second model we assume that the chance, that a country has a high happyScore is influenced by its characteristics such as income inequality, gdp and median income.*

3.3. **Write down the mathematical formula for each of the models** -\> 2p each –\> 4p total

> *answer: model1: happyScore = b0 + b1\*income_inequality+b2\*gdp+b3\*median_income*
>
> *answer: model2: high_happyScore = b0 + b1\*income_inequality+b2\*gdp+b3\*median_income*

3.4. **Interpret the coefficients for the models** (value, meaning, significance), use two post decimal positions–\> 2p per coefficient –\> 4 coefficients per model (0.5 per element) –\> 4\*0,5\*3 -\> 6p per model -\> 12p total

```{r}
options(scipen = 999)
linear_model <- lm(happyScore~income_inequality+gdp+median_income,data=happiness_income_data_clean)
summary(linear_model)
```

> *answer: Interpretation model1:*
>
> | coefficients                        | interpretation                                                                                                                                                                                                                                                      |
> |----------------------------------|--------------------------------------|
> | (Intercept) 3.244930846\*\*\*       | When all other variables are 0 the happyScore is approximately 3.24p. there is no meaningful explanation in our case. The value is highly significant on the 99.9% level.                                                                                           |
> | income_inequality 0.031412802\*\*\* | Keeping all other values stable the happyScore increases approx. 0.03p with each additional point of income inequality. This means that a rise in income inequality slightly increases the happyScore. The value is highly significant on the 99.9% level.          |
> | gdp -0.000008244 -                  | Keeping all other values stable the happyScore lowers by 0.000008244p if the gdp rises by 1 unit, meaning by 1 trillion. This value is not significant on any of the standard levels (p = 0.77) and therefore has little explanatory power.                         |
> | median_income 0.000183292\*\*\*     | Keeping all other values stable the happyScore rises approx. by 0.000183292 points with each additional dollar in median income. This means that a rise in the median income increases the happyScore slightly. The value is highly significant on the 99.9% level. |

```{r}
#logistic regression for "happy country" or not
happiness_income_data_clean$high_happyScore <- ifelse(happiness_income_data_clean$happyScore>=7, 1, 0)

logistic_model <- glm(high_happyScore ~ income_inequality+gdp+median_income, family = binomial, data=happiness_income_data_clean)
summary(logistic_model)
```

# Task 4: Regularization and Generalizability - 18p

Given the linear regression models below, answer the following questions:

happyScore = $\beta_1$ income_inequality + $\beta_2$ gdp + $\beta_3$ median_income

#### 4.1 Feature Selection with Regularization (6 points)

4.1.1 Suppose you want to use **Ridge** or **Lasso regression** to reduce overfitting and to identify the most important predictors. Say, income_inequality and median_income are highly correlated. How might the coefficients ($\beta_1$ and $\beta_3$) change if you use ridge regression? (3p)

> **Answer:** Ridge regression will shrink their coefficients proportionally, reducing their individual contributions but keeping both predictors in the model.

4.1.2 What about lasso regression? (3p)

> **Answer:** Ridge regression will shrink their coefficients proportionally, reducing their individual contributions but keeping both predictors in the model.

#### 4.2 Generalizability Testing (6 points)

4.2.1 Generalizability refers to models' ability to make correct predictions on unseen data. Given the happiness_income_data_clean dataset, please describe a method to evaluate the **generalizability** of the linear regression model. (2p)

> **Answer**: split the data into training, validation and/or testing set; apply validation method such as k-fold cross-validation

4.2.2 Given the following results from a 5-fold cross-validation, calculate the average R-squared value. (2p)

| **Fold** | **R-squared Value** |
|----------|---------------------|
| Fold 1   | 0.85                |
| Fold 2   | 0.85                |
| Fold 3   | 0.84                |
| Fold 4   | 0.83                |
| Fold 5   | 0.83                |

> **Answer:** (0.85 + 0.85 + 0.84 + 0.83 + 0.83) / 5 = 0.84
>
> 4.2.3. What does this average, combined with the consistency of the fold results, tell you about the model's ability to generalize? (2p)
>
> **Answer**: The average R-squared value of 0.84indicates that, on average, the model explains 84% of the variance in the data, which suggests good predictive performance. The results are consistent across the folds (with values ranging from 0.83 to 0.85), showing that the model performs reliably on different subsets of the data. This consistency indicates that the model generalizes well to unseen data and is not overfitting or underfitting.

#### 4.3 **Decision Tree Construction (6 points)**

Given the following dataset for predicting happiness score (HappyScore) based on **GDP** and **Income Inequality** (all variables are categorical variables), draw the decision tree you would construct for predicting HappyScore based on GDP and Income Inequality. (6p)

| **GDP** | **Income Inequality** | **HappyScore** |
|---------|-----------------------|----------------|
| Low     | High                  | Low            |
| Low     | Medium                | High           |
| Low     | Low                   | High           |
| Medium  | High                  | Low            |
| Medium  | Medium                | Low            |
| Medium  | Low.                  | Low            |
| High    | High                  | Low            |
| High    | Medium                | Low            |
| High    | Low                   | High           |

> **Answer**:
>
> ![](images/tree.drawio.png)
