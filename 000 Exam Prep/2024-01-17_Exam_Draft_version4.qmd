---
title: "Exam draft (first exam) Ws 24/25"
format: 
  html:
    self-contained: true
    theme: minty
editor: visual
---

# Task 1: MC Questions (30p)

15 questions, 2p per question -\> 30p

::: callout-note
Please note, that multiple (max. 2) or single answers are possible.
:::

## Task 1.1

Working with R: Given the following matrix in R: `matrix_data <- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3, byrow = TRUE)`. Which R code returns the number of columns in this matrix?

a.  `ncol(matrix_data)`
b.  `nrow(matrix_data)`
c.  `length(matrix_data)`
d.  `dim(matrix_data)[2]`

**Answer:**

a\. `ncol(matrix_data)`

## Task 1.2

Algorithms: What is the main purpose of an algorithm?

a.  Database management
b.  Automatic generation of graphics
c.  Solving a problem through a sequence of steps
d.  Implementation of hardware components

**Answer:**

c\. Solving a problem through a sequence of steps

## Task 1.3

Model validation: What is a fundamental step in model validation in Data Science?

a.  Train the model
b.  Collect data
c.  Verify the accuracy of the model with new data
d.  Save the model in a database

**Answer:**

c\. Verify the accuracy of the model with new data (Junbo: i will rather say model performance instead of accuracy)

## Task 1.4

Model performance: Which term describes the ability of a model to perform well on unseen data?

a.  Overfitting
b.  Generalization
c.  Data cleaning
d.  Underfitting

**Answer:**

b\. Generalization

## Task 1.5

**What does 'pruning' refer to in the context of decision trees?**

a.  Increasing the number of features considered in the model to provide more complexity.

b.  Aggregating the results of multiple decision trees into a single model for better accuracy.

c.  Refining the model by removing branches that do not significantly contribute to predictive power

d.  Utilizing cross-validation techniques to determine significant branches.

**Answer:**

c\. Refining the model by removing branches that do not significantly contribute to predictive power

## Task 1.6

**What does dimensionality reduction refer to in data science?**

a.  Expanding the dataset with additional features
b.  removing large values from a dataset
c.  Streamlining the analysis by focusing on a smaller number of relevant variables
d.  Filtering out all categorical variables from the dataset.

**Answer:**

c\. Streamlining the analysis by focusing on a smaller number of relevant variables

## Task 1.7

Which package in R is commonly used for creating advanced graphics?

a.  ggplot2
b.  dplyr
c.  tidyr
d.  shiny

**Answer:**

a\. ggplot2

## Task 1.8

In R, what function is commonly used to transform data into a data frame?

a.  matrix()
b.  as.data.frame()
c.  df()
d.  table()

**Answer**:

b\. as.data.frame()

## Task 1.9 +

What is the primary purpose of a validation set in data science?

a\. To train the model on labeled data. b. To evaluate the model's performance during training. c. To test the model's final performance on unseen data. d. To preprocess and clean the dataset.

**Answer:**

b\. To evaluate the model's performance during training.

## Task 1.10 +

What is the main objective of regularization as seen in ridge/lasso regression?

a.  To improve training speed by reducing the dataset size.
b.  To handle missing values in the dataset effectively.
c.  To prevent overfitting by penalizing large model coefficients.
d.  To increase the complexity of the model for better accuracy.

**Answer:**

c\. To prevent overfitting by penalizing large model coefficients.

## Task 1.11 ++

In regularization techniques like Ridge and Lasso regression, what effect does increasing the regularization parameter (\$\lambda\$) have on the model?

a.  It increases the complexity of the model by allowing larger coefficients.
b.  It reduces the magnitude of coefficients, leading to simpler models and less overfitting.
c.  It has no impact on the model's coefficients or complexity.
d.  It increases the model's sensitivity to noise in the training data.

**Answer:**

b\. It reduces the magnitude of coefficients, leading to simpler models and less overfitting.

## Task 1.12 +

What type of problem is logistic regression primarily used to solve?

a.  Regression problems where the target variable is continuous.
b.  Classification problems where the target variable is categorical.
c.  Clustering problems where the data is grouped into clusters.
d.  Dimensionality reduction problems.

**Answer**:

b\. Classification problems where the target variable is categorical.

## Task 1.13 +++

Which of the following assumptions is not a requirement for linear regression to produce valid and unbiased results?

a.  Linearity: The relationship between the predictors and the target variable is linear.
b.  Homoscedasticity: The variance of the residuals is constant across all levels of the predictors.
c.  Multicollinearity: Predictors should be highly correlated with each other to improve model stability.
d.  Independence: The residuals are independent of each other.

**Answer**:

c\. Multicollinearity: Predictors should be highly correlated with each other to improve model stability.

## Task 1.14 +

Which of the following metrics is most commonly used to evaluate the goodness of fit in a linear regression model?

a.  Accuracy
b.  Mean Squared Error (MSE)
c.  F1-score
d.  Precision

**Answer** : b. Mean Squared Error (MSE)

## Task 1.15 +++

When evaluating the performance of a linear regression model, which of the following statements about R-squared (R²) is incorrect?

a.  R² measures the proportion of the variance in the dependent variable that is explained by the independent variables.
b.  A higher R² value indicates a better fit of the model to the data.
c.  R² can never be negative.
d.  R² increases when adding more predictors to the model, even if those predictors do not improve the model.

**Answer**:

c\. R² can never be negative.

## Task 1.16 ++

In Ordinary Least Squares (OLS) linear regression, which of the following does Residual Sum of Squares (RSS) measure? The equation for RSS is:

```{=tex}
\begin{equation}
RSS = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\end{equation}
```
a.  The total variance explained by the model.
b.  The difference between the predicted and actual values of the dependent variable.
c.  The sum of squared errors between the observed and predicted values.
d.  The amount of variance not explained by the regression model.

**Answers**:

c\. The sum of squared errors between the observed and predicted values.

d\. The amount of variance not explained by the regression model.

## Task 1.17 +++

When comparing multiple linear regression models, which of the following statements are the most accurate regarding **R-squared (R²)** and **Mean Squared Error (MSE)**?

a\. R² is always the best metric to use when comparing models, regardless of the context.\
b. A higher R² always indicates a better model, even if it leads to overfitting.\
c. MSE is a better metric for evaluating model performance on unseen data.\
d. R² and MSE are used to directly compare models that have different numbers of predictors.

**Answers:**\
c. MSE is a better metric for evaluating model performance on unseen data.\
d. R² and MSE are used to directly compare models that have different numbers of predictors.

## Task 1.18 +

In the context of data science, which of the following best describes the concept of **generalizability**?

a\. The ability of a model to perfectly predict the target variable for the training data.\
b. The ability of a model to identify patterns in a dataset that can be applied to other similar datasets.\
c. The ability of a model to memorize specific examples from the training data.\
d. The ability to visualize and interpret the training data in multiple ways.

**Answer:**\
b. The ability of a model to identify patterns in a dataset that can be applied to other similar datasets.

## Task 1.19 +

Which of the following are symptoms of **overfitting** in a linear regression model?

a\. The model performs well on training data but poorly on unseen test data.\
b. The model has high bias and performs poorly on both training and test data.\
c. The model performs well on both training and test data.\
d. The model has high variance and captures noise in the training data.

**Answers:**\
a. The model performs well on training data but poorly on unseen test data.\
d. The model has high variance and captures noise in the training data.

## Task 1.20 ++

After fitting a linear regression model in R using the `lm()` function, you obtain the following output for the model coefficients:

$$\text{(Intercept)} = 5.2, \quad \beta_1 = 2.4, \quad \beta_2 = -0.8$$ Given this model:

$$ \hat{y} = 5.2 + 2.4 \times X_1 - 0.8 \times X_2$$

What can be inferred from $\beta_1$ in this model?

a.  For each unit increase in $X_1$, the predicted value of $y$ will increase by 5.2.
b.  For each unit increase in $X_1$, the predicted value of $y$ will increase by 2.4, assuming $X_2$ remains constant.
c.  For each unit increase in $X_2$, the predicted value of $y$ will decrease by 0.8, assuming $X_1$ remains constant.
d.  The value of $y$ is independent of $X_1$ and only depends on $X_2$.

**Correct Answer:**\
b. For each unit increase in $X_1$, the predicted value of $y$ will increase by 2.4, assuming $X_2$ remains constant.

c\. For each unit increase in $X_2$, the predicted value of $y$ will decrease by 0.8, assuming $X_1$ remains constant.

# Task 2: Code explanation - 20p

The task consists of two elements with 10p each.

We will work with `happiness_income_data`. This dataset includes information about different countries and income, satisfaction of the inhabitants, the GDP, income inequality and other variables.

```{r}
#| echo: false

library(readr)
happiness_income_data <- read_csv("happyscore_income.csv")
#View(happiness_income_data)
happiness_income_data$country...11 <- NULL
happiness_income_data$country <- happiness_income_data$country...1
happiness_income_data$country...1 <- NULL
```

```{r}
#| echo: false
library(openxlsx)
gdp_clean <- read.xlsx("GDP_clean_2023.xlsx")
gdp_clean$GDP_2023 <- as.numeric(gdp_clean$GDP_2023)
gdp_clean$gdp <- gdp_clean$GDP_2023/1000000000
gdp_clean$country <- gdp_clean$Country.Name
gdp_clean$Country.Name <- NULL
gdp_clean$GDP_2023 <- NULL

happiness_income_data <- merge(happiness_income_data, gdp_clean, by.x = "country", by.y="country", all.x = TRUE)

happiness_income_data$GDP <- NULL

happiness_income_data_orig <- happiness_income_data

```

```{r}
#| echo: false
data <- data.frame(
  adjusted_satisfaction = c(37, NA, 60, 59, 65, NA, 43, 63, 37, 34),
  avg_satisfaction = c(4.9, NA, 7.1, 7.2, 7.6, NA, 5.3, 7.2, 4.4, 4.6),
  std_satisfaction = c(2.42, 3.19, 1.91, NA, 1.80, 5.0, 2.10, 1.72, 2.02, 2.57),
  avg_income = c(2096.760, NA, 7101.120, 19457.040, 19917.000, NA, 
                 1265.340, 17168.505, 870.840, 5354.820),
  median_income = c(-999, NA, 5109.400, 16879.620, 15846.060, NA, 
                    994.140, 15166.455, 630.240, 4523.565),
  income_inequality = c(31.44556, NA, -20.56, 30.29625, 35.28500, NA, 
                        32.66500, 113.5, 39.76000, 34.16250),
  region = c('Central and Eastern Europe', 'Sub-Saharan Africa', 
             'Latin America and Caribbean', 'Western Europe', 
             'Australia and New Zealand', NA, 'Southern Asia', 
             'Western Europe', 'Sub-Saharan Africa', 
             'Central and Eastern Europe'),
  happyScore = c(4.350, NA, 12.32, 7.200, 7.284, NA, 4.694, -6.937, 
                 3.587, 4.218),
  gdp = c(14.08, NA, 800, NA, -1.3, NA, 0.39753, 
          261.4, 0.25812, NA),
  country = c('Malawi', 'Zambia', 'Guatemala', 'Sierra Leone', 
              'Panama', NA, 'Burundi', 'Kazakhstan', 
              'Ghana', 'Laos')
)


happiness_income_data <- rbind(happiness_income_data, data)

#install.packages("openxlsx")
#library(openxlsx)
#write.xlsx(happiness_income_data, 'export.xlsx')
```

Data Description:

The dataset consists of 111 observations. You will work with a sample (task 2.1) and the full data set (task 2.2 and task 2).

| name                  | valuetype | scale                  | explanation                                                                                             |
|-----------------------|-----------|------------------------|---------------------------------------------------------------------------------------------------------|
| adjusted_satisfaction | numeric   | 0 to 100               | lower values indicate lower life satisfaction, higher values indicate higher life satisfaction          |
| avg_income            | numeric   | 0\$ to thousands of \$ | average annual income in \$                                                                             |
| median_income         | numeric   | 0\$ to thousands of \$ | median annual income in \$                                                                              |
| income_inequality     | numeric   | 0 to 100               | income inequality, lower values indicate a lower inequality, higher values indicate a higher inequality |
| happyScore            | numeric   | 0-10                   | lower values indicate a lower overall happiness, higher values indicate a higher overall happiness      |
| gdp                   | numeric   |                        | GDP in trillions of \$ (Milliarden auf deutsch)                                                         |
| country               | character | \-                     | country name                                                                                            |

## Task 2.1

a.  The following code snippet works with the data set `happiness_income_data`. You see a sample of this original data set below. Some transformations and selections etc. were made - trace those steps and execute them manually to fill in the sampled data table by hand. Your result represents happiness_data_clean and includes the same observations as the original sample (8p)

    ```{r}
       # load("happiness_income_data.RData") #loading data
    load("happiness_income_data.RData")

    happiness_income_data$happyScore <- ifelse(happiness_income_data$happyScore > 10, NA, happiness_income_data$happyScore)

    happiness_income_data$median_income <- ifelse(happiness_income_data$median_income < 0, NA, happiness_income_data$median_income)

    happiness_income_data$income_inequality <- ifelse(happiness_income_data$income_inequality < 0 | happiness_income_data$income_inequality > 100, NA, happiness_income_data$income_inequality)

    happiness_income_data_clean <- na.omit(happiness_income_data)

    ```

![](images/clipboard-2896833125.png)

a.  Did you remove singular values and/or rows and/or columns? If you did so, explain why. (2p)
b.  Did you add singular values and/or rows and/or columns? If you did so, explain why. (2p)
c.  Did you change the content or name of singular values and/or rows and/or columns? If you did so, explain why. (2p)
d.  After applying the code: Are any values left that could potentially lead to problems? If so, how could we fix that problem (answer verbally, no code needed)? (2p)

## Task 2.2 - 4p

After the listed data transformation steps we apply a linear regression to our full data set (111 observations) and are left with this output:

```{r}
#| echo: false
happiness_income_data_clean <- happiness_income_data_orig 
happiness_income_data_clean <- na.omit(happiness_income_data_clean)
#make sure the students have the dataset with real values, not the missings/errors that were intentionally included in task 1.1
summary(happiness_income_data_clean)
```

```{r}
options(scipen=999)
model1 <- lm(adjusted_satisfaction ~ avg_income, happiness_income_data_clean)
summary(model1)
```

a.  Which of these graphs best illustrates the results of the linear regression (model1)? (1p)

b.  Why are the other graphics not suitable? (1p each)

    Graph 1

    ```{r}
    #| echo: false

    library(ggplot2)
      ggplot(data=happiness_income_data_clean, mapping = aes(x=avg_income, y=adjusted_satisfaction)) +
        geom_point() +
        geom_smooth(method = lm, formula = y ~ x) +
        scale_x_continuous(breaks = seq(0, 25000, 1000)) +
        scale_y_continuous(breaks = seq(0, 80, 10)) +
      theme(axis.text.x = element_text(angle = 45), axis.text.y = element_text(angle = 45)) +
        xlab("average annual income in $") +
        ylab("adjusted satisfaction")
    ```

Graph 2

```{r}
#| echo: false
library(ggplot2)
ggplot(data=happiness_income_data_clean, mapping = aes(x = avg_income, y=adjusted_satisfaction)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2)) +
 xlab("average annual income in $") +
    ylab("adjusted satisfaction")

```

Graph 3

```{r}
#| echo: false
library(ggplot2)
ggplot(data=happiness_income_data_clean, mapping = aes(x = avg_income, y=adjusted_satisfaction)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ poly(x, 7)) +
 xlab("average annual income in $") +
    ylab("adjusted satisfaction")

```

Graph 4

```{r}
#| echo: false
ggplot(data=happiness_income_data_clean, mapping = aes(x=avg_income, y=adjusted_satisfaction)) +
    geom_point() +
    geom_smooth(method = lm) +
    theme(axis.ticks = element_blank(),     
          axis.text.x = element_blank(),
          axis.text.y = element_blank()) +
 xlab("average annual income in $") +
    ylab("adjusted satisfaction")
```

# Task 3: Regression - 25p

1.  What kind of question do the different models answer? Think of a research question for model1 and of a research question for model2. (2p each) –\> 4p total
2.  Explain each model in your own words –\> 2,5p each –\> 5p total
3.  Write down the mathematical formula for each of the models -\> 2p each –\> 4p total
4.  Interpret the coefficients for the models (value, meaning, significance)–\> 2p per coefficient –\> 4 coefficients per model (0.5 per element) –\> 4\*0,5\*3 -\> 6p per model -\> 12p total

```{r}
options(scipen = 999)
linear_model <- lm(happyScore~income_inequality+gdp+median_income,data=happiness_income_data_clean)
summary(linear_model)
```

```{r}
#logistic regression for "happy country" or not
happiness_income_data_clean$high_happyScore <- ifelse(happiness_income_data_clean$happyScore>=7, 1, 0)

logistic_model <- glm(high_happyScore ~ income_inequality+gdp+median_income, family = binomial, data=happiness_income_data_clean)
summary(logistic_model)
```

### Bonus Questions with the above dataset:

#### 1. Feature Selection with Regularization (4 points)

Suppose you use **Ridge** or **Lasso regression** on the linear regression model (as the following equation) to identify the most important predictors in the above dataset

happyScore = $\beta_1$ income_inequality + $\beta_2$ gdp + $\beta_3$ median_income

Say, income_inequality and median_income are highly correlated. How might the coefficients change if you use ridge regression? What about lasso regression?

**Answer:** Ridge regression will shrink their coefficients proportionally, reducing their individual contributions but keeping both predictors in the model. Lasso, on the other hand, may set one coefficient (e.g., median income) to zero, effectively removing it and prioritizing GDP.

#### 2. Generalizability Testing (3 points)

Describe a method to evaluate the **generalizability** of the linear regression model in Task 3.

**Answer**: split the data into training, validation and/or testing set; apply validation method such as k-fold cross-validation
